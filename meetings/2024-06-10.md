# FP SIG meeting minutes - 2024-06-10

Presents:
    Kenneth Rovers (Imagination)
    Al Martin (Akeana)
    Cay Blomqvist (individual)
    Michael Kennedy (Qualcomm)
    Nicolas Brunie (SiFive)    
    
Agenda:
        - RISC-EU Summit
        - AI on RISC-V
        - scalar-vs

RISC-EU summit coming up end of June: No members of the SIG (in this meeting) are going to be there [but we should keep in mind that summits can be a good opportunity for the SIG or a subset to meet in person]

Webinar: AI on RISC-V
- Kenneth is preparing a webinar on RISC-V and AI
- Driven by Imagination and sponsored by RVIA
- Will reach out to AI/ML work group

Discussion: RISC-V support for BF16
- Adding a scalar extension offering the same support as the F extension but for the BFloat16 format
    - Is there any need for this type of extension ?
    - What are the expected benefits ?
    - No throughput benefit
- BF16 and other smaller floating-point formats may only be really used/useful in vector operations
- Scalar BF operations could be used to:
    - [KR]: Unify support with vector (e.g. allow cores without vector to support code "migration" from vector code)
    - [AM]: Support the implementation of accurate exception handler than can iterate over a vector that has raised FP flags during FP16 operation [software emulation]
    
Does scalar BF16 support exist in the wild ? (In RISC-V or other ISAs)
    - [KR]: Imagination has a scalar BF16 extension [core besides a Neural accelerator that support special function not handled by the accelerator]
    - [AM]: Another opportunity might be for a packed BF16 (4 BF16 operations per instruction, exploiting FLEN-wide registers)
    - [NB] This looks like something that would be part of a floating-point extension of the P extension
Conclusion on BF16 discussion
    The SIG wants to ask its members and RVIA members to share their interest and ideas for a BF16 extension

Discussion: Scalar-vector consistency
- Document prepared by Al https://docs.google.com/spreadsheets/d/1pZ3oJVDHkV-ndsuaMZ9b_TxVF3wluYKALHectlryEbk/edit?usp=sharing
- No strong driver (at the moment) 
There might be some interests for vector Zfa
[AM]: Some instructions from Zfa , such as fminm, fmaxm might be useful in vector
[KR]: This seems easy enough to suggest, will need to be backed by data
[NB]: Not all instructions would be interesting

The SIG could gather evidence of a critical mass of interest behind this project
Might be easier if we reach out to software / compiler people to get feedback on such projects

Open actions:
- [ ] Kick off the effort for vector Zfa on the mailing list [AM]
- [ ] Send messages to mailing list to gather interest/feedback on effort for FP8 and BF16 [KR, NB]
- [x] Send BF16 paper to mailing list (Kenneth)
- [ ] Reach out to SW & tools about BF16 C-support
- [~] Is it desirable to in general keep vector and scalar floating point support in sync?
    - Do we need a vector version of Zfa?
- [ ] Check with AI/ML, HPC and vector SIGs for recent updates
- [~] Understand software tools and industry needs (partly done)
- [~] Do we need Zfbfwma?
- [ ] Understand status, quality, coverage of testing frameworks, i.e. ACT (how to identify gaps in testing framework for floating point)
- [~] How to map an increasing number of formats to a limited opcode space (e.g. what goes to the very limited compressed 16-bit)
- [~] Look at available opcode space, opcode vs CSR mode
